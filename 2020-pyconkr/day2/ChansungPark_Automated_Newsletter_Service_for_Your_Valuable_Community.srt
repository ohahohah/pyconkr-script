1
00:00:10,640 --> 00:00:13,280
Hello everybody, welcome to my session.

2
00:00:14,800 --> 00:00:19,040
My name is Chansung Park, and
I am one of the administrators

3
00:00:19,040 --> 00:00:21,120
at TensorFlow Korea community.

4
00:00:21,920 --> 00:00:25,360
Today I'm here to share my own experience

5
00:00:25,360 --> 00:00:28,800
on how I have improved the
quality of the community

6
00:00:28,800 --> 00:00:31,200
by creating something as shown in title,

7
00:00:31,760 --> 00:00:33,280
Automated Newsletter Service.

8
00:00:34,400 --> 00:00:37,360
This newsletter service
is an open source project,

9
00:00:37,920 --> 00:00:42,400
and was built specifically for
TensorFlow Korea community.

10
00:00:43,120 --> 00:00:45,440
But you'll see some general concepts

11
00:00:45,440 --> 00:00:48,480
and the way how to apply
it for your own community.

12
00:00:51,200 --> 00:00:54,640
So here are some of the topics
that I wanna cover today.

13
00:00:54,640 --> 00:00:57,200
First, I wanna give a
little bit of background

14
00:00:57,760 --> 00:01:00,400
about what TensorFlow Korea community is

15
00:01:00,400 --> 00:01:02,880
in order to give you sense of what it is,

16
00:01:02,880 --> 00:01:05,280
and why the newsletter
service might be a good thing.

17
00:01:06,640 --> 00:01:09,600
Second, I'll share some of my experiences,

18
00:01:10,480 --> 00:01:13,200
mostly bad experiences while interacting

19
00:01:13,200 --> 00:01:15,520
with the community over the past one year.

20
00:01:16,400 --> 00:01:21,920
By doing so, you'll understand what exactly
motivated me to create such service.

21
00:01:22,960 --> 00:01:25,840
Third, I'm going through some
of the implementation details,

22
00:01:26,800 --> 00:01:30,400
this is not about giving you
how to write the actual code,

23
00:01:30,400 --> 00:01:36,400
but to give you a sense, what are
the components needed to form such service,

24
00:01:36,400 --> 00:01:39,840
and what are the pipelines
looks like to run the service.

25
00:01:40,640 --> 00:01:43,200
The fourth one is a
part of the third topic,

26
00:01:43,840 --> 00:01:45,600
the newsletter service could be run

27
00:01:45,600 --> 00:01:48,240
as a standalone application locally,

28
00:01:48,960 --> 00:01:52,480
but it would be nice to send
out newsletters automatically.

29
00:01:52,480 --> 00:01:56,160
You'll see how we can
leverage GitHub Action

30
00:01:56,160 --> 00:01:58,960
for automated weekly newsletter service.

31
00:02:00,720 --> 00:02:05,200
And last but not least,
I'll give you a brief talk

32
00:02:05,200 --> 00:02:07,840
about the current status of the service,

33
00:02:08,400 --> 00:02:11,200
and the future plan that
I'm working on these days

34
00:02:11,200 --> 00:02:13,120
to improve the service any further.

35
00:02:14,480 --> 00:02:15,440
So let's begin.

36
00:02:17,040 --> 00:02:20,880
TensorFlow Korea is a community originated

37
00:02:20,880 --> 00:02:24,160
for sharing information and experiences

38
00:02:24,160 --> 00:02:25,840
about TensoerFlow framework.

39
00:02:26,560 --> 00:02:30,080
TensorFlow code is an open source project

40
00:02:30,080 --> 00:02:33,840
and is for machine learning
and deep learning project.

41
00:02:34,720 --> 00:02:36,960
And it was created by Google, by the way,

42
00:02:37,920 --> 00:02:39,760
it's based on Facebook group,

43
00:02:39,760 --> 00:02:43,680
and it started out its
own journey in 2016,

44
00:02:43,680 --> 00:02:45,520
I mean, TensorFlow Korea community

45
00:02:45,520 --> 00:02:48,320
not the TensorFlow
framework, that was just

46
00:02:48,320 --> 00:02:52,080
an year after the born
of TensorFlow framework.

47
00:02:53,360 --> 00:02:58,560
And we have reached about
50,000 members about a month ago.

48
00:02:59,200 --> 00:03:02,960
It was a very important
milestone for our community,

49
00:03:02,960 --> 00:03:05,920
so the newsletter service
that I will explain

50
00:03:05,920 --> 00:03:13,360
was designed for celebrating and returning
back event for our community members.

51
00:03:15,040 --> 00:03:17,040
Despite of its original purpose,

52
00:03:17,600 --> 00:03:22,960
there is a variety of topics that
we discuss these days in our community.

53
00:03:24,240 --> 00:03:27,440
As you know, AI itself is not a big deal,

54
00:03:27,440 --> 00:03:31,200
but when it's combined with
different technologies,

55
00:03:31,200 --> 00:03:32,800
it becomes a huge deal.

56
00:03:34,160 --> 00:03:37,120
Because of that, we have
a very large user base

57
00:03:37,120 --> 00:03:38,880
from lots of different backgrounds.

58
00:03:39,920 --> 00:03:43,600
Interesting part is,
our members are posting

59
00:03:43,600 --> 00:03:48,880
not only simple Q&As but also
complex topics and some useful information.

60
00:03:49,600 --> 00:03:52,960
They're labeled by very
rich text and images.

61
00:03:54,080 --> 00:03:57,600
There's quite different aspect
from other communities, I think.

62
00:03:59,200 --> 00:04:03,360
Also we are holding lots of
great events online and offline.

63
00:04:04,240 --> 00:04:06,400
During the COVID-19 pandemic,

64
00:04:06,400 --> 00:04:09,840
we have held awesome
on-tech online seminars

65
00:04:09,840 --> 00:04:12,160
with a Leader of Google AI advocate,

66
00:04:12,160 --> 00:04:15,520
Professor Cho Kyunghyun
from New York University,

67
00:04:15,520 --> 00:04:18,560
and NVIDIA engineer from Silicon Valley.

68
00:04:20,160 --> 00:04:22,560
Let me show you some of the showcases

69
00:04:22,560 --> 00:04:25,840
that we frequently share
through this community.

70
00:04:26,800 --> 00:04:28,160
Most of all, as you can see,

71
00:04:28,720 --> 00:04:31,920
many posts are very
rich and well organized.

72
00:04:32,640 --> 00:04:35,360
On the right hand side,
ah, on the left hand side,

73
00:04:35,360 --> 00:04:40,480
the screenshot shows that we share
some news that's happening globally,

74
00:04:40,480 --> 00:04:43,760
and encourage members
to join the discussion via comments.

75
00:04:44,640 --> 00:04:47,760
Also, since members use
lots of different tools

76
00:04:47,760 --> 00:04:51,440
to realize AI for their own purpose,

77
00:04:52,080 --> 00:04:55,040
we wanna share tips and useful
information about the tools.

78
00:04:55,840 --> 00:05:01,120
This is not just for TensorFlow framework,

79
00:05:01,120 --> 00:05:02,560
but it's for everything.

80
00:05:02,560 --> 00:05:04,560
You can frequently find out information

81
00:05:04,560 --> 00:05:08,080
related to PyTorch, Jags
and other frameworks,

82
00:05:08,640 --> 00:05:09,840
and whatever you're looking for.

83
00:05:11,600 --> 00:05:14,480
And this kind of post sometimes includes

84
00:05:15,040 --> 00:05:19,200
the actual code snippets,
I think it is super useful.

85
00:05:20,080 --> 00:05:22,800
The third example is a bit crazy, but yes,

86
00:05:22,800 --> 00:05:25,280
some of our members are researchers,

87
00:05:25,280 --> 00:05:28,160
and they're happy to share paper reviews,

88
00:05:28,160 --> 00:05:29,680
and their own thoughts about it.

89
00:05:30,320 --> 00:05:33,600
We actually have a group
of people recording

90
00:05:33,600 --> 00:05:38,240
and sharing their paper
reviews every week.

91
00:05:38,240 --> 00:05:41,520
Also, ethical issue is
an important part in AI.

92
00:05:42,720 --> 00:05:44,400
As shown for the example,

93
00:05:44,960 --> 00:05:48,880
our members want to share
ethical topics and eager

94
00:05:48,880 --> 00:05:52,160
to listen to what other
people think about the topics.

95
00:05:53,280 --> 00:05:57,680
AI is rapidly evolving area,
so it's also good thing

96
00:05:57,680 --> 00:06:03,440
to have some people who share
recent trends and their limitations.

97
00:06:04,320 --> 00:06:09,600
Now, these are just a tiny bit of what's
happening in TensorFlow Korea community,

98
00:06:10,400 --> 00:06:14,480
but by looking at these examples,
you could get some sense

99
00:06:14,480 --> 00:06:19,920
that we have very rich
information floating around.

100
00:06:19,920 --> 00:06:23,760
So this was the first thing
that developed my intuition

101
00:06:23,760 --> 00:06:25,520
to create the newsletter service,

102
00:06:26,720 --> 00:06:30,240
because I didn't wanna lose
all the information after all.

103
00:06:31,200 --> 00:06:33,280
As you know, it's not easy to hold

104
00:06:33,280 --> 00:06:35,040
past information in Facebook though.

105
00:06:37,920 --> 00:06:40,880
Here, let's look at
some numbers this time.

106
00:06:40,880 --> 00:06:42,720
By inspecting some numbers,

107
00:06:42,720 --> 00:06:47,840
this idea could be developed
much more concrete and strong.

108
00:06:49,120 --> 00:06:50,640
On the top left corner,

109
00:06:50,640 --> 00:06:54,240
the graph shows constantly
increasing number of members,

110
00:06:54,960 --> 00:06:59,920
meaning we are possibly having more
and more people to share rich information.

111
00:07:00,960 --> 00:07:06,160
Also we have a constant number
of active members over the last year,

112
00:07:06,800 --> 00:07:10,960
this clearly shows many of our members are
happy about the community.

113
00:07:12,160 --> 00:07:15,840
On the right hand side, you
can see there are two graphs

114
00:07:16,480 --> 00:07:20,320
showing the number of
posts for the past 60 days

115
00:07:20,320 --> 00:07:22,320
and seven days respectively.

116
00:07:23,200 --> 00:07:28,240
As you can see, we have a
list of 150 posts every week,

117
00:07:28,240 --> 00:07:31,360
you might think it is small
number, when you think about

118
00:07:31,360 --> 00:07:34,720
the number of members 50,000.

119
00:07:35,520 --> 00:07:37,360
However, this is a huge number,

120
00:07:37,360 --> 00:07:40,960
when you think about how well
the information is refined

121
00:07:40,960 --> 00:07:43,840
as seen from the showcase.

122
00:07:45,760 --> 00:07:50,880
As you can see, TensorFlow
Korea is a pretty good place

123
00:07:50,880 --> 00:07:54,720
by looking at some of the statistical
numbers and actual showcase.

124
00:07:55,280 --> 00:07:59,040
However, it turns out Facebook
group is not a great place

125
00:07:59,040 --> 00:08:01,920
to archive and search
past information.

126
00:08:02,800 --> 00:08:05,120
I wouldn't even have come up with the idea

127
00:08:05,120 --> 00:08:08,480
to create a newsletter service if not so.

128
00:08:09,520 --> 00:08:11,840
Who wants to share nicely
formatted information,

129
00:08:12,480 --> 00:08:15,600
if it'll be dead the information
like after a month or so?

130
00:08:16,960 --> 00:08:20,720
Here are some of the drawbacks
that I wanna point out,

131
00:08:20,720 --> 00:08:22,080
which inspired me a lot.

132
00:08:23,040 --> 00:08:27,120
These are drawbacks specifically
curated for Facebook Group,

133
00:08:27,120 --> 00:08:30,160
but this might not be
true for your community.

134
00:08:30,960 --> 00:08:35,440
But if you think your community
coincidentally has similar issues,

135
00:08:35,440 --> 00:08:40,720
you could consider creating
a similar service for your own community.

136
00:08:41,360 --> 00:08:45,360
At the end, I'll let you know how to bring
this open source project

137
00:08:45,360 --> 00:08:46,880
into your own community.

138
00:08:48,320 --> 00:08:52,320
So Facebook recommends what to
read for each Facebook user.

139
00:08:53,040 --> 00:08:56,560
And Facebook keeps recommending
what you should read

140
00:08:56,560 --> 00:08:58,000
based on your interest.

141
00:08:58,800 --> 00:09:02,560
It's hard to keep following topics
that you have a little interest.

142
00:09:03,360 --> 00:09:05,360
This could be a useful feature

143
00:09:05,360 --> 00:09:08,160
if you wanna read what you're up to only.

144
00:09:08,720 --> 00:09:11,520
However, in the case
that you want to expand

145
00:09:11,520 --> 00:09:16,640
your interest to other areas,
that might be a bad feature.

146
00:09:17,440 --> 00:09:20,240
According to the nature of our community,

147
00:09:20,240 --> 00:09:22,800
this feature seems very inappropriate.

148
00:09:23,600 --> 00:09:25,920
Like I said before, our members

149
00:09:25,920 --> 00:09:28,080
have many different backgrounds,

150
00:09:28,080 --> 00:09:30,400
so they are kind of new to AI field.

151
00:09:31,520 --> 00:09:36,320
Also, consider the numbers that we
have just discussed in the previous slide,

152
00:09:36,320 --> 00:09:38,240
it's almost impossible to consume

153
00:09:38,800 --> 00:09:41,120
more than 150 posts every week,

154
00:09:41,920 --> 00:09:44,560
even with top few posts like 20,

155
00:09:44,560 --> 00:09:48,640
just ask yourself that
you could really digest

156
00:09:48,640 --> 00:09:51,520
those information in a week, probably not,

157
00:09:52,400 --> 00:09:56,960
especially when information
is not simple, but very rich.

158
00:09:57,920 --> 00:10:01,520
Fixing these drawbacks could
led TensorFlow Korea community

159
00:10:01,520 --> 00:10:03,840
to become much better place.

160
00:10:04,880 --> 00:10:08,560
Also all the administrators
at TensorFlow Korea

161
00:10:08,560 --> 00:10:10,720
always keep paying attention

162
00:10:10,720 --> 00:10:13,360
to what we could give back
to our community members.

163
00:10:15,760 --> 00:10:18,600
So with this background
in mind, I have created

164
00:10:18,600 --> 00:10:21,840
a newsletter service to
solve some of those problems.

165
00:10:22,720 --> 00:10:27,120
Here is a quick overview of it,
it is not a complicated service

166
00:10:27,120 --> 00:10:30,720
nor it requires a lot
of Python coding skills

167
00:10:30,720 --> 00:10:33,600
like it only took about
three weeks to launch.

168
00:10:34,800 --> 00:10:38,640
Rather, it was just designed
to deliver rich information

169
00:10:38,640 --> 00:10:41,040
to as many people as possible.

170
00:10:42,160 --> 00:10:45,520
After receiving newsletters,
it is up to receivers

171
00:10:45,520 --> 00:10:50,240
to archive if they want by
using a simple functions

172
00:10:50,240 --> 00:10:53,360
in their mailbox like tagging function.

173
00:10:54,320 --> 00:10:59,920
Out of 150 weekly posts,
up to 20 posts gets ranked

174
00:10:59,920 --> 00:11:02,080
by a simple summation formula,

175
00:11:04,640 --> 00:11:07,600
the number of reactions,
the number of shares,

176
00:11:07,600 --> 00:11:08,960
and the number of comments.

177
00:11:10,400 --> 00:11:13,120
It's possible to give
weights for each parameter,

178
00:11:13,120 --> 00:11:15,680
so there's a customizable point.

179
00:11:16,640 --> 00:11:22,480
For TensorFlow Korea, they're all set
to one for now, as an experimental purpose.

180
00:11:23,520 --> 00:11:26,480
Also one of the great
features about this service

181
00:11:26,480 --> 00:11:29,280
is the ability to issue
a weekly newsletter

182
00:11:29,280 --> 00:11:31,280
without a human being involved.

183
00:11:32,080 --> 00:11:34,320
That means it's fully automated,

184
00:11:34,320 --> 00:11:36,240
and it's done through GitHub action.

185
00:11:37,280 --> 00:11:44,160
I'll give a talk about
this topic just in shortly.

186
00:11:46,640 --> 00:11:49,360
I have included all the
details about this project

187
00:11:49,360 --> 00:11:53,520
in README, I think the
documentation has done nicely.

188
00:11:54,320 --> 00:11:58,880
In the document, you can read the CLI spec

189
00:11:58,880 --> 00:12:04,160
for this program, and I
believe CLI is the best way

190
00:12:04,160 --> 00:12:08,240
to understand any project
features in a high level view.

191
00:12:09,200 --> 00:12:11,120
So here's a sneak peek at it.

192
00:12:12,720 --> 00:12:14,960
As you can see, there are some options

193
00:12:14,960 --> 00:12:18,240
to make application
behave in different ways.

194
00:12:18,960 --> 00:12:23,040
As we can set the range of dates when the,

195
00:12:23,040 --> 00:12:25,840
to be scrapped post or posted by

196
00:12:25,840 --> 00:12:27,600
using since then until flags.

197
00:12:28,320 --> 00:12:31,840
Also, we could limit the
number of post to scrap.

198
00:12:32,880 --> 00:12:36,160
Again, the weights for
each, different parameters

199
00:12:37,440 --> 00:12:41,280
for the number of
reactions, number of shares,

200
00:12:41,280 --> 00:12:44,320
number of comments are
all configurable as well.

201
00:12:46,000 --> 00:12:47,200
On the right hand side,

202
00:12:47,200 --> 00:12:50,320
the screenshot shows
a sample example uses,

203
00:12:50,320 --> 00:12:52,400
so please check it out
if you're interested.

204
00:12:55,760 --> 00:12:59,600
That was a pretty high level features
of what the application does.

205
00:13:00,400 --> 00:13:04,080
Let's dive into bit more
details about the pipeline,

206
00:13:04,080 --> 00:13:07,040
how the whole system
actually works in a nutshell.

207
00:13:08,240 --> 00:13:13,280
The first thing it tries to do is
to read configurations from external files.

208
00:13:14,000 --> 00:13:17,600
Configurations are split
into two categories,

209
00:13:17,600 --> 00:13:20,240
sensitive and nonsensitive.

210
00:13:20,240 --> 00:13:22,960
There are a number of
sensitive information,

211
00:13:23,520 --> 00:13:25,920
including Facebook access token,

212
00:13:25,920 --> 00:13:29,320
SMTP related information and et cetera.

213
00:13:29,320 --> 00:13:32,000
Nonsensitive information is all about

214
00:13:32,640 --> 00:13:37,520
what you can customize like
the number of top posts to be included,

215
00:13:38,080 --> 00:13:41,600
how many words to include
for each post, and more.

216
00:13:42,720 --> 00:13:44,320
Based on the configuration,

217
00:13:44,320 --> 00:13:47,040
it tries to scrap Facebook
post in the group.

218
00:13:47,600 --> 00:13:50,640
The returning values from Facebook server

219
00:13:50,640 --> 00:13:52,480
are expressed in JSON format.

220
00:13:53,120 --> 00:13:55,680
So we need to parse them
into Python objects.

221
00:13:56,480 --> 00:14:01,280
The next step is to inject
parsed data into email template

222
00:14:01,280 --> 00:14:03,840
which consists of HTML and CSS,

223
00:14:04,640 --> 00:14:07,280
and injection is done
through Jinja2 library.

224
00:14:08,960 --> 00:14:12,720
The next step is to send out

225
00:14:12,720 --> 00:14:15,840
the formed email template
to the subscribers.

226
00:14:16,400 --> 00:14:19,200
At this point, the main goal
will be achieved nicely.

227
00:14:19,920 --> 00:14:22,800
But as you can see, there
are two additional steps,

228
00:14:23,760 --> 00:14:27,200
refreshing Facebook token
and write configurations.

229
00:14:28,720 --> 00:14:32,720
Refreshing Facebook tokens
are something inconvenient,

230
00:14:32,720 --> 00:14:34,960
but necessary for some reasons.

231
00:14:34,960 --> 00:14:37,360
I'll talk a bit more about that shortly.

232
00:14:38,880 --> 00:14:42,160
"Write configuration" is to
update the Facebook token

233
00:14:42,160 --> 00:14:45,360
with the refreshed one
into an external file

234
00:14:46,160 --> 00:14:49,280
to make sure the token wouldn't
be expired in the next time,

235
00:14:50,400 --> 00:14:53,520
because the token persist
for a certain range of time

236
00:14:54,160 --> 00:14:58,320
so in order to keep everything works fine
after a week later,

237
00:14:59,040 --> 00:15:01,600
a new token that will be still alive

238
00:15:03,040 --> 00:15:07,440
should be written down
to the configuration file.

239
00:15:09,760 --> 00:15:13,040
So this slide shows the
structure of the project.

240
00:15:13,040 --> 00:15:15,600
Let me go through one by one real quick.

241
00:15:16,400 --> 00:15:19,520
There are two directories, lib and static.

242
00:15:19,520 --> 00:15:22,880
I put every internal logics
into a lib directory.

243
00:15:23,680 --> 00:15:27,280
This includes data object
model, parsing logics,

244
00:15:27,280 --> 00:15:30,480
creating email templates,
sending emails and so on.

245
00:15:31,600 --> 00:15:36,000
On the other hand, I put something
without a logic into static folder.

246
00:15:37,120 --> 00:15:42,160
It's more like constant
value stores in one place,

247
00:15:42,160 --> 00:15:45,120
HTML templates are stored in here too.

248
00:15:46,880 --> 00:15:49,680
Other than that, there are just
two more interesting files,

249
00:15:50,480 --> 00:15:55,760
that env.gpg and config.cfg,
which are responsible

250
00:15:55,760 --> 00:15:59,120
for sensitive and non sensitive
information respectively.

251
00:16:00,000 --> 00:16:03,840
Just for experimental purpose
and self-learning purpose,

252
00:16:03,840 --> 00:16:07,360
I have chosen that and that m-Python

253
00:16:07,920 --> 00:16:11,360
and standard config parser package

254
00:16:11,360 --> 00:16:15,280
for each file to insert and
extract information from them.

255
00:16:16,560 --> 00:16:20,080
The remaining files are
pretty much self-explanatory,

256
00:16:20,080 --> 00:16:23,840
so I don't think I need to give
any further explanations about them.

257
00:16:26,880 --> 00:16:30,320
So let's talk about configuration now.

258
00:16:31,280 --> 00:16:34,560
Like I said, there are two
separate configuration files.

259
00:16:35,600 --> 00:16:39,600
In a development phase,
configurations are something

260
00:16:39,600 --> 00:16:41,920
that should be changed very often time.

261
00:16:42,800 --> 00:16:46,960
And it is the central place
where other users can touch

262
00:16:46,960 --> 00:16:50,240
to port the project into
their own situations.

263
00:16:51,120 --> 00:16:52,880
So I have found that keeping

264
00:16:52,880 --> 00:16:56,560
the two very different information
separately is a good practice.

265
00:16:57,200 --> 00:16:59,840
I don't wanna make any
difference whenever possible

266
00:16:59,840 --> 00:17:04,560
for like application ID,
application secrete,

267
00:17:04,560 --> 00:17:06,000
Facebook access token,

268
00:17:06,560 --> 00:17:09,360
which should remain as
the same all the time.

269
00:17:10,480 --> 00:17:14,960
Let's think about that,
I don't separate those.

270
00:17:15,760 --> 00:17:18,480
Even though I'm not going
to change the information

271
00:17:19,680 --> 00:17:23,040
that should remain as the same,
I should save it

272
00:17:23,040 --> 00:17:25,920
and sync with the remote repository

273
00:17:25,920 --> 00:17:29,040
whenever I modify
the configurable information.

274
00:17:29,920 --> 00:17:35,200
Further more, sensitive information is
designed to be encrypted via GPG,

275
00:17:35,200 --> 00:17:40,160
which stands for GNU Privacy Guard,
a server encryption algorithm.

276
00:17:40,160 --> 00:17:43,600
After encryption is done,
all the information stays

277
00:17:43,600 --> 00:17:46,320
as the same except for
the Facebook access token,

278
00:17:47,120 --> 00:17:50,240
and passphrases managed to
GitHub secret by the way,

279
00:17:51,280 --> 00:17:53,520
where you can put secret values

280
00:17:53,520 --> 00:17:55,280
and reference back and GitHub Action,

281
00:17:55,840 --> 00:17:59,280
so that you can decrypt that GPG file

282
00:17:59,280 --> 00:18:02,160
with the passphrase without
letting anyone know about it.

283
00:18:03,840 --> 00:18:09,600
On the other hand, config.cfg file
contains all the customizable information.

284
00:18:10,400 --> 00:18:14,960
Just for your information,
Top K means the number of posts

285
00:18:14,960 --> 00:18:18,640
to appear in a newsletter,
which is set to 24-hour.

286
00:18:19,360 --> 00:18:23,920
And most importantly, Facebook
group ID is the ID of a group

287
00:18:24,560 --> 00:18:26,400
where you wanna scrap post from.

288
00:18:27,040 --> 00:18:31,280
The name of keys are pretty
much self-explanatory,

289
00:18:31,280 --> 00:18:34,640
so please read it, if
you're interested in.

290
00:18:34,640 --> 00:18:38,240
But let me move on to
the next topic for now,

291
00:18:38,240 --> 00:18:41,840
which is Facebook access token.

292
00:18:43,280 --> 00:18:48,240
Facebook access token is
something that you must acquire

293
00:18:48,240 --> 00:18:50,880
if you wanna use Facebook Graph API.

294
00:18:51,840 --> 00:18:56,480
In a normal process, you can
get the Facebook access token

295
00:18:56,480 --> 00:18:58,800
for three major steps like,

296
00:18:59,360 --> 00:19:01,280
you should create an Facebook app,

297
00:19:02,320 --> 00:19:05,520
you should request on certain features

298
00:19:05,520 --> 00:19:08,400
like group API for your app,

299
00:19:09,440 --> 00:19:12,960
and your app must be
reviewed by Facebook team.

300
00:19:13,920 --> 00:19:16,320
It doesn't look very
complicated process at all.

301
00:19:17,600 --> 00:19:21,440
But the problem is, during
the COVID-19 pandemic,

302
00:19:21,440 --> 00:19:22,880
Facebook has made a decision

303
00:19:22,880 --> 00:19:27,200
to temporarily pause individual
verification process,

304
00:19:27,200 --> 00:19:30,320
meaning you can't get the
access token in a normal way.

305
00:19:31,280 --> 00:19:34,480
I was kind of shocked by
the fact because I was like,

306
00:19:34,480 --> 00:19:37,040
how I get a post back from Facebook now,

307
00:19:37,040 --> 00:19:38,160
is that even possible?

308
00:19:39,600 --> 00:19:42,880
But luckily, after playing
around with the Facebook API

309
00:19:42,880 --> 00:19:45,520
and reading Facebook official documents,

310
00:19:45,520 --> 00:19:47,760
I found there's a workaround for this.

311
00:19:48,400 --> 00:19:49,360
It goes like this.

312
00:19:50,640 --> 00:19:53,760
First, you grab a temporary access token

313
00:19:53,760 --> 00:19:59,120
via Graph API Explorer, which
is a playground for Graph API.

314
00:20:00,480 --> 00:20:04,400
Exchange the temporary access
token with a long lived one,

315
00:20:04,400 --> 00:20:07,040
Facebook provides an API for this.

316
00:20:07,920 --> 00:20:10,240
Temporary access token only leaves

317
00:20:10,240 --> 00:20:12,080
up to less than a day or so,

318
00:20:12,080 --> 00:20:15,200
but the long lived one lives
up to more than a week.

319
00:20:15,920 --> 00:20:20,560
So whenever graphing and parsing
Facebook post with the current token,

320
00:20:21,760 --> 00:20:24,240
the current token will get refreshed

321
00:20:24,240 --> 00:20:27,120
for the next run for the one more week,

322
00:20:27,680 --> 00:20:30,640
because this is a weekly
newsletter service.

323
00:20:32,000 --> 00:20:34,400
The refreshed token will be exported

324
00:20:34,400 --> 00:20:37,280
into the dotenv and encrypted via gpg.

325
00:20:38,640 --> 00:20:41,040
This was why we needed
two additional steps

326
00:20:41,040 --> 00:20:43,040
at the end of the whole pipeline.

327
00:20:44,880 --> 00:20:49,600
And this slide is for a snippet of
knowledge about Facebook's Graph API.

328
00:20:50,480 --> 00:20:53,360
Graph API is nothing but a graph structure

329
00:20:53,360 --> 00:20:55,920
that you probably studied
from algorithm class.

330
00:20:56,560 --> 00:20:58,000
Everything can be expressed

331
00:20:58,000 --> 00:21:02,080
with three concepts, node, edge and field.

332
00:21:02,080 --> 00:21:05,760
Node is an entity and
the edge is a connection,

333
00:21:05,760 --> 00:21:07,440
between nodes and fields

334
00:21:08,000 --> 00:21:11,360
is a piece of information
dangling within a node.

335
00:21:11,920 --> 00:21:16,320
For instance, group is a
node and posts are nodes,

336
00:21:16,320 --> 00:21:18,960
and there are edges
between a group and posts.

337
00:21:19,840 --> 00:21:25,840
And each post contains a number of fields
like date, contents, and so on.

338
00:21:26,880 --> 00:21:28,800
It is somewhat a hard concept

339
00:21:28,800 --> 00:21:30,720
when you have never heard about before.

340
00:21:31,520 --> 00:21:34,960
Also, the version has been
dramatically changed over time.

341
00:21:36,400 --> 00:21:40,080
And it already has reached version 8.0.

342
00:21:41,200 --> 00:21:46,480
You might have read various
news about digital privacy,

343
00:21:46,480 --> 00:21:50,880
so Facebook continuously
addressed new policies,

344
00:21:50,880 --> 00:21:53,280
but the problem is that
they don't really make

345
00:21:53,280 --> 00:21:58,640
any big announcement about
it for their developers.

346
00:22:00,560 --> 00:22:06,160
But luckily, the only lucky
part and hope is that,

347
00:22:06,160 --> 00:22:11,840
there is a graph API
Explorer as a place that

348
00:22:11,840 --> 00:22:15,600
you can play with APIs, so
please use it whenever possible.

349
00:22:17,520 --> 00:22:21,200
There's a tip for developers
who wanna deal with Facebook API.

350
00:22:24,000 --> 00:22:27,360
So after parsing configuration,
what's gonna happen?

351
00:22:28,720 --> 00:22:30,320
It's kind of boring steps.

352
00:22:30,960 --> 00:22:34,240
But almost always, you
need a similar procedure,

353
00:22:34,240 --> 00:22:37,520
when you try to scrap
information through API,

354
00:22:37,520 --> 00:22:40,320
or crawling, is not
just only for Facebook.

355
00:22:43,920 --> 00:22:48,240
Make HTTP requests to Facebook
server, is a good practice

356
00:22:48,240 --> 00:22:51,440
to make this function
asynchronously working

357
00:22:51,440 --> 00:22:54,560
because you don't want other
functions to be blocked.

358
00:22:56,000 --> 00:22:58,960
And Facebook server
will give you back data

359
00:22:58,960 --> 00:23:01,440
in the response which is in JSON format.

360
00:23:02,160 --> 00:23:03,760
Because a raw JSON data

361
00:23:04,320 --> 00:23:07,760
is not really accessible in Python, right?

362
00:23:07,760 --> 00:23:12,080
So it should be properly
parsed into Python objects.

363
00:23:12,880 --> 00:23:15,280
There are multiple ways
to achieve this goal,

364
00:23:15,280 --> 00:23:18,800
but I have found it is easier
and much more readable

365
00:23:19,520 --> 00:23:21,840
if you make a class method for this.

366
00:23:22,720 --> 00:23:24,800
So class method is a central place,

367
00:23:26,720 --> 00:23:32,320
which takes the incoming
raw JSON data format file.

368
00:23:33,440 --> 00:23:37,360
And it extracts all the
information from the JSON,

369
00:23:37,360 --> 00:23:42,960
and it creates an instance
of the Python object

370
00:23:42,960 --> 00:23:45,440
if the JSON data is valid.

371
00:23:46,160 --> 00:23:52,240
Based on parsed data, it'll
create a data model instance, like I said,

372
00:23:52,240 --> 00:23:55,280
so that all the information
is much more accessible

373
00:23:55,840 --> 00:23:57,760
for the rest of the program logics.

374
00:24:02,960 --> 00:24:05,200
Based on parsed data within data model,

375
00:24:05,760 --> 00:24:08,960
we can now inject them into HTML template.

376
00:24:09,520 --> 00:24:12,640
HTML/CSS is easy, right?

377
00:24:12,640 --> 00:24:18,080
But when it gets too long,
is not easily manageable,

378
00:24:18,080 --> 00:24:21,840
even it gets worse when you
download a template from online,

379
00:24:22,480 --> 00:24:25,360
because they contain some weird characters

380
00:24:25,360 --> 00:24:27,280
that only their system understands.

381
00:24:28,400 --> 00:24:34,800
Like Jinja2, we can split HTML
into several pieces of HTMLs

382
00:24:35,360 --> 00:24:40,560
is like managing and importing
multiple sources of files in one project.

383
00:24:41,280 --> 00:24:45,520
Also Jinja2 is probably
the most popular way

384
00:24:45,520 --> 00:24:48,640
to inject Python information into HTML,

385
00:24:49,280 --> 00:24:52,320
very flexible, and there
are nothing much to learn.

386
00:24:53,840 --> 00:24:57,200
So which means syntax is straightforward,

387
00:24:57,200 --> 00:24:59,840
so you could learn it just in a day.

388
00:25:00,400 --> 00:25:04,880
I have additionally used Markdown2 package
before information injection.

389
00:25:05,760 --> 00:25:08,720
Markdown2 is a tool to convert

390
00:25:08,720 --> 00:25:12,400
an article written in
markdown format in HTML form.

391
00:25:13,360 --> 00:25:17,840
Because basically, Facebook's posts
are written in Markdown format.

392
00:25:18,560 --> 00:25:21,360
It won't be rendered appropriately,

393
00:25:21,360 --> 00:25:25,040
if we don't make Markdown
syntax to be HTML compatible.

394
00:25:25,600 --> 00:25:32,080
For instance, one hash character
often means a heading in Markdown.

395
00:25:32,080 --> 00:25:36,400
But h1 tag is the counterpart in HTML.

396
00:25:36,400 --> 00:25:41,840
So the so hash characters
should be converted into h1 tag.

397
00:25:42,640 --> 00:25:45,920
Premailer packages also necessary package

398
00:25:47,040 --> 00:25:50,240
if you consider email service,

399
00:25:50,240 --> 00:25:52,960
since every CSS style should be in line

400
00:25:52,960 --> 00:25:55,920
as attributes of every HTML tags,

401
00:25:55,920 --> 00:25:59,440
that's a kind of normal thing in an email.

402
00:26:00,400 --> 00:26:03,600
Otherwise almost every email clients

403
00:26:03,600 --> 00:26:05,920
will not render things nicely,

404
00:26:05,920 --> 00:26:07,920
and something will probably be broken.

405
00:26:09,200 --> 00:26:11,760
I have not mentioned about the first step

406
00:26:11,760 --> 00:26:14,000
in the email templating pipeline much,

407
00:26:14,880 --> 00:26:17,120
it's all about your searching ability

408
00:26:17,120 --> 00:26:19,360
to find out the best template.

409
00:26:21,120 --> 00:26:23,840
But it's a real time consuming job,

410
00:26:24,880 --> 00:26:29,040
if you don't have enough
skills in HTML and CSS,

411
00:26:29,760 --> 00:26:31,360
looking for template line,

412
00:26:32,160 --> 00:26:34,960
consider how much time
is going to be wasted.

413
00:26:36,240 --> 00:26:41,360
For me, a week out of the whole
three weeks for this project

414
00:26:41,360 --> 00:26:43,840
were wasted for only this process.

415
00:26:46,320 --> 00:26:50,960
It's very fortunate to have free
service like Google Groups,

416
00:26:51,760 --> 00:26:53,920
Google Groups is a central place

417
00:26:53,920 --> 00:26:56,720
to dispatch an email to all subscribers.

418
00:26:57,360 --> 00:27:03,120
So I just need to email the HTML template
to our Google Groups

419
00:27:03,120 --> 00:27:06,880
and everyone in the group
will get the same email.

420
00:27:09,360 --> 00:27:17,680
If you are planning to dispatch one email
template to a lot of people out there,

421
00:27:18,640 --> 00:27:22,640
and wanna make sure they're
getting the same email all the time,

422
00:27:23,200 --> 00:27:25,360
please use Google Groups.

423
00:27:25,360 --> 00:27:27,440
I think that's the best solution for this.

424
00:27:31,040 --> 00:27:33,520
So that is pretty much
everything you should know

425
00:27:33,520 --> 00:27:35,600
about how to build a newsletter service.

426
00:27:36,720 --> 00:27:39,360
This slide is kind of side note

427
00:27:39,360 --> 00:27:41,360
to let you know what GitHub Action is,

428
00:27:42,000 --> 00:27:44,400
and how we can make the job automatic.

429
00:27:44,960 --> 00:27:49,920
First of all, you can choose
free or paid version for GitHub Action,

430
00:27:49,920 --> 00:27:53,600
but you are almost always be satisfied
with the free version,

431
00:27:54,560 --> 00:27:55,680
I guarantee you.

432
00:27:56,800 --> 00:27:58,480
As you can see from the table,

433
00:27:58,480 --> 00:28:01,440
there are only differences
about the size of storage

434
00:28:01,440 --> 00:28:03,760
and running minutes of GitHub Action.

435
00:28:04,880 --> 00:28:08,720
2000 minutes per month should
be enough for most of you.

436
00:28:09,600 --> 00:28:15,840
You can also choose an operating
system for your needs too.

437
00:28:16,720 --> 00:28:21,520
But just remember other
specs like CPU, RAM size,

438
00:28:22,640 --> 00:28:25,440
other hardware specs
are, they're all the same

439
00:28:26,400 --> 00:28:29,840
between the paid version and free version.

440
00:28:31,200 --> 00:28:34,720
One particular reason that I
like about GitHub Action is,

441
00:28:34,720 --> 00:28:39,840
I can easily overview how the
process goes in a project,

442
00:28:40,560 --> 00:28:44,320
meaning GitHub Action illustrates
the high level workflow.

443
00:28:45,200 --> 00:28:49,200
And it's very important
when you analyze an open source project.

444
00:28:51,840 --> 00:28:54,560
I will probably say
this is the first place

445
00:28:54,560 --> 00:28:57,680
that I'll visit for
any open source project

446
00:28:57,680 --> 00:28:59,840
if they use GitHub Action.

447
00:29:01,600 --> 00:29:04,800
However, one of the
drawbacks is the difficulties

448
00:29:04,800 --> 00:29:06,880
during the GitHub Action testament,

449
00:29:06,880 --> 00:29:10,160
you get to find out a way
to test Github Action locally.

450
00:29:10,720 --> 00:29:14,160
Otherwise, you'll probably
end up with something

451
00:29:14,160 --> 00:29:19,120
like 150 commits from this
slide, as you can see.

452
00:29:21,680 --> 00:29:26,400
100 out of 150 reflects
the number of changes

453
00:29:26,400 --> 00:29:29,440
that are needed to experiment
with a GitHub Action.

454
00:29:30,320 --> 00:29:34,960
Luckily, recently I have found
there are a couple of ways

455
00:29:34,960 --> 00:29:37,760
that you can test in a local environment.

456
00:29:37,760 --> 00:29:40,640
One way is to pull GitHub Action event

457
00:29:40,640 --> 00:29:43,600
from their local machine, and do something

458
00:29:43,600 --> 00:29:45,920
within your local machine
based on the event.

459
00:29:46,720 --> 00:29:48,880
That is the recommended way to do

460
00:29:49,680 --> 00:29:52,480
and you can find the
information how to do it

461
00:29:52,480 --> 00:29:55,920
from the GitHub Action official document.

462
00:29:56,720 --> 00:30:00,560
The other way is to
leverage "nektos/act" project

463
00:30:00,560 --> 00:30:02,480
which should lest you test

464
00:30:02,480 --> 00:30:05,040
the whole GitHub Action
environment locally.

465
00:30:06,480 --> 00:30:08,640
So please, for further information,

466
00:30:08,640 --> 00:30:12,400
check out the official document
on "nektos/act" project homepage.

467
00:30:15,920 --> 00:30:20,720
This slide shows the definition of
the GitHub Action workflow for this project.

468
00:30:21,680 --> 00:30:24,800
Like I said, just by reading each line,

469
00:30:24,800 --> 00:30:27,280
you'll understand the high level overview

470
00:30:27,280 --> 00:30:29,040
about how this project works.

471
00:30:29,680 --> 00:30:32,480
For instance, let's look
at the left hand side.

472
00:30:33,520 --> 00:30:38,400
GitHub Action is scheduled
to be run every Friday at 3:00 AM,

473
00:30:38,400 --> 00:30:40,800
which is 12:00 pm in South Korea.

474
00:30:42,053 --> 00:30:43,600
Is just a simple cron job.

475
00:30:44,240 --> 00:30:46,080
If you're familiar with cron job

476
00:30:46,080 --> 00:30:49,840
from the Linux operating
system, is super easy.

477
00:30:51,280 --> 00:30:57,200
Let me go through one red line
by one on the right hand side.

478
00:30:57,200 --> 00:30:59,360
In order to pull encrypted information

479
00:30:59,360 --> 00:31:03,840
from .M.GPG, it should
be decrypted first, right?

480
00:31:04,800 --> 00:31:06,720
And some environment variables

481
00:31:06,720 --> 00:31:10,320
are set to be used as
arguments of the main program.

482
00:31:12,080 --> 00:31:14,400
That's the second red line.

483
00:31:15,280 --> 00:31:17,680
And program gets run and the email

484
00:31:17,680 --> 00:31:20,720
should be successfully sent
by the end of this process.

485
00:31:21,520 --> 00:31:24,320
And the access token
should be refreshed by now,

486
00:31:24,320 --> 00:31:28,160
with a new one for the next one more week.

487
00:31:29,040 --> 00:31:32,960
The refreshed token gets
written down to the .env

488
00:31:32,960 --> 00:31:36,480
and .env will be encrypted again via GPG.

489
00:31:37,280 --> 00:31:39,840
Since .env gpg is updated,

490
00:31:39,840 --> 00:31:42,000
it should be pushed to the master branch.

491
00:31:42,560 --> 00:31:45,920
So the update information will persist
for the next one more week.

492
00:31:47,520 --> 00:31:48,800
It is very straightforward

493
00:31:48,800 --> 00:31:51,680
and you'll get the sense how
the program really works.

494
00:31:55,680 --> 00:31:58,800
We have explored how program works

495
00:31:58,800 --> 00:32:01,040
but you got to consider the privacy issue

496
00:32:01,040 --> 00:32:03,040
before working on the actual project.

497
00:32:03,760 --> 00:32:07,040
If your app is going to
violate some privacy issues,

498
00:32:07,920 --> 00:32:10,080
then your application will be useless

499
00:32:10,080 --> 00:32:12,640
after spending a whole month to build one.

500
00:32:13,520 --> 00:32:16,000
This is all about ownership of each post

501
00:32:16,000 --> 00:32:19,840
and is like a question,
can they be exposure

502
00:32:19,840 --> 00:32:21,760
without any permission or something?

503
00:32:22,720 --> 00:32:25,920
Fortunately, everything publicly posted

504
00:32:25,920 --> 00:32:28,480
can be shared without any
permission in Facebook,

505
00:32:29,120 --> 00:32:30,240
that is the policy.

506
00:32:31,280 --> 00:32:33,680
This is not a great thing to know about

507
00:32:33,680 --> 00:32:35,760
as an individual Facebook user,

508
00:32:36,560 --> 00:32:40,160
but it may be nice to
know as an app developer.

509
00:32:41,680 --> 00:32:44,080
TensorFlow Korea is a public group

510
00:32:44,080 --> 00:32:47,040
and everything in it is also public,

511
00:32:47,600 --> 00:32:49,600
so there were no problems at all

512
00:32:50,160 --> 00:32:51,920
to launch this newsletter service.

513
00:32:53,600 --> 00:32:55,840
I have found the supporting documents

514
00:32:56,400 --> 00:32:59,920
through Facebook's Help
page and also I have found

515
00:32:59,920 --> 00:33:03,120
some attorneys from the
US have confirmed it.

516
00:33:03,680 --> 00:33:07,440
So please check the privacy issue
before diving into the implementation

517
00:33:08,000 --> 00:33:10,240
unless your group is based on Facebook.

518
00:33:13,040 --> 00:33:14,880
I'll skip over this slide a bit,

519
00:33:14,880 --> 00:33:20,080
but it shows how to port this project
for your own community.

520
00:33:20,080 --> 00:33:23,840
So it looks like there are
too many things to configure.

521
00:33:25,360 --> 00:33:28,560
But actually, the only things
that should be modified

522
00:33:28,560 --> 00:33:30,720
are information about your Facebook group.

523
00:33:31,520 --> 00:33:33,520
You cannot avoid from this,

524
00:33:33,520 --> 00:33:37,120
no matter what you're going
to build for Facebook,

525
00:33:37,120 --> 00:33:38,960
is a total necessary step.

526
00:33:40,160 --> 00:33:45,200
Even though, you're going to
build some other application

527
00:33:45,200 --> 00:33:49,280
for Facebook other than
this newsletter service.

528
00:33:50,080 --> 00:33:55,360
Like Facebook group ID, Facebook
app ID, application secret

529
00:33:56,080 --> 00:33:58,960
also you should include
SMTP related information

530
00:33:58,960 --> 00:34:00,560
to send email to somebody.

531
00:34:02,240 --> 00:34:05,520
You don't really need to
modify the source code at all though,

532
00:34:05,520 --> 00:34:08,640
if you don't wanna make any change,

533
00:34:08,640 --> 00:34:11,200
like email design or parsing logic.

534
00:34:12,880 --> 00:34:15,600
However, if your group
is not based on Facebook,

535
00:34:15,600 --> 00:34:18,080
you should probably
modify the parsing logic,

536
00:34:18,080 --> 00:34:20,640
requests and logics and et cetera.

537
00:34:20,640 --> 00:34:22,800
Also, you've got to find out the way

538
00:34:22,800 --> 00:34:25,520
you can request, post the
information to the server.

539
00:34:26,240 --> 00:34:28,640
Maybe there should be some APIs

540
00:34:28,640 --> 00:34:32,800
or you could build your own web crawler.

541
00:34:33,520 --> 00:34:35,280
I'll recommend to do it so though.

542
00:34:40,240 --> 00:34:44,560
So this project has been on service
for the last two months or so.

543
00:34:44,560 --> 00:34:48,640
We have reached more than
500 subscribers in a month,

544
00:34:49,280 --> 00:34:51,600
and I think yes
it is still not small number,

545
00:34:52,160 --> 00:34:54,640
but not bad as the first attempt.

546
00:34:55,280 --> 00:35:00,440
I assume many members still not even
aware of existence of this service.

547
00:35:00,440 --> 00:35:03,760
I am planning to improve
newsletter service

548
00:35:03,760 --> 00:35:06,480
by applying deep learning in near future.

549
00:35:07,200 --> 00:35:10,240
This pipeline shows a simple MLOps

550
00:35:10,240 --> 00:35:12,720
which is like DevOps for
machine learning project.

551
00:35:14,080 --> 00:35:18,560
The core idea is to classify
each post into categories

552
00:35:18,560 --> 00:35:23,200
like research, news,
Q&A, tools and et cetera,

553
00:35:23,200 --> 00:35:26,080
by leveraging NLP model like BERT.

554
00:35:27,280 --> 00:35:31,840
It is to avoid some post
with not much helpful information

555
00:35:31,840 --> 00:35:33,840
to be included in the newsletter.

556
00:35:35,280 --> 00:35:38,080
Because the current system grab everything

557
00:35:38,080 --> 00:35:41,680
without knowing what categories they are,

558
00:35:42,880 --> 00:35:46,400
so for example,
some events like sharing out

559
00:35:46,400 --> 00:35:51,520
newly published books are
sometimes included as the top one rank.

560
00:35:52,640 --> 00:35:56,000
I think this kind of information
is not real important to anyone

561
00:35:56,560 --> 00:35:59,200
if the event has been closed already.

562
00:36:01,360 --> 00:36:04,640
Leveraging NLP model is a trivial job,

563
00:36:04,640 --> 00:36:09,520
I can just make and deploy
one useless model easily.

564
00:36:09,520 --> 00:36:12,160
However, since the characteristics of post

565
00:36:13,040 --> 00:36:16,720
on a community gets evolved
and changed over time,

566
00:36:16,720 --> 00:36:19,760
the model should be retrained
to avoid to be outdated.

567
00:36:21,280 --> 00:36:24,160
So DVC and CML are simple,

568
00:36:24,720 --> 00:36:27,440
but nice projects to tackle this problem.

569
00:36:29,200 --> 00:36:32,400
With DVC, which stands
for Data Version Control,

570
00:36:32,400 --> 00:36:34,640
you can manage versions of data.

571
00:36:34,640 --> 00:36:37,600
But data here doesn't mean
the training data only,

572
00:36:38,160 --> 00:36:41,120
but it also can support the management

573
00:36:41,120 --> 00:36:42,720
of versioning deep learning model.

574
00:36:43,520 --> 00:36:45,280
Actually, it can manage everything

575
00:36:45,280 --> 00:36:49,520
that is too large to be
stored in GitHub repository.

576
00:36:51,040 --> 00:36:54,400
It manages the version of
file which is actually stored

577
00:36:54,400 --> 00:36:57,360
in Google Drive or storage platform,

578
00:36:57,360 --> 00:37:00,400
you will also need to keep meta information

579
00:37:01,040 --> 00:37:02,560
and a GitHub repository.

580
00:37:02,560 --> 00:37:06,720
That's the only requirement to achieve
this data version controlling stuff.

581
00:37:07,760 --> 00:37:10,240
CML is continuous machine learning,

582
00:37:10,240 --> 00:37:13,440
is not thing but to
report training results

583
00:37:13,440 --> 00:37:15,840
with a set of rich information like graph

584
00:37:16,480 --> 00:37:18,960
as a GitHub PRs command.

585
00:37:19,680 --> 00:37:23,760
Based on this report, we can
decide whether to merge the PR.

586
00:37:24,560 --> 00:37:28,560
So when new data arrives, it
will trigger GitHub Action

587
00:37:28,560 --> 00:37:30,080
to train a model on a data.

588
00:37:31,120 --> 00:37:34,560
After training is done,
the reports will be posted

589
00:37:34,560 --> 00:37:37,760
as a GitHub PRs command via CML.

590
00:37:38,480 --> 00:37:41,520
By looking at it, we can
decide to merge the PR,

591
00:37:41,520 --> 00:37:45,120
and when it is merged, it'll
trigger another GitHub Action

592
00:37:45,120 --> 00:37:50,080
to create new endpoint
for the most recently pretrained model.

593
00:37:51,600 --> 00:37:54,720
The reason to make
everything work automatic is,

594
00:37:54,720 --> 00:37:58,560
there is a chance that I 'll
quit the administrator position

595
00:37:58,560 --> 00:38:00,880
at TensorFlow Korea
community at some point.

596
00:38:01,520 --> 00:38:05,600
When it happens, I won't
hand this project over to someone else,

597
00:38:05,600 --> 00:38:11,600
and let him or her to manage
this project with a minimal effort.

598
00:38:12,960 --> 00:38:17,040
Or hopefully no one should
really look much in details

599
00:38:17,040 --> 00:38:18,960
or not a human being involved at all.

600
00:38:19,920 --> 00:38:22,560
If you find yourself being
interested in this project,

601
00:38:23,360 --> 00:38:25,920
please find it by searching my ID,

602
00:38:25,920 --> 00:38:27,840
deep dash diver in GitHub.

603
00:38:29,280 --> 00:38:31,840
There are lots of contribution points.

604
00:38:32,640 --> 00:38:36,720
And I need help, and thank you.

605
00:38:38,400 --> 00:38:39,280
Thanks for listening,

606
00:38:39,280 --> 00:38:43,040
I hope this presentation
has given you a valuable information.

607
00:38:44,640 --> 00:38:51,520
Thank you for listening a lot.

608
00:38:51,520 --> 00:38:52,020
See you.

